{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BERT_Webinar.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN8AD8HuMtLJpGy74LhL9Be"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"yu-QsRn3Sj2o","colab_type":"text"},"source":["This was made by following along with the webinar posted here: https://www.youtube.com/watch?v=NoixdExFb7Y&t=7349s"]},{"cell_type":"code","metadata":{"id":"ClulWD1EaLpO","colab_type":"code","outputId":"854e71f8-d973-49a9-b4d3-6a02cbbcbf14","executionInfo":{"status":"ok","timestamp":1580236532615,"user_tz":300,"elapsed":5814,"user":{"displayName":"Michael Gunn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDLPGDDbbM21TTQ016rwUebXbiYn0V96tePqWjuFA=s64","userId":"01288302193981142685"}},"colab":{"base_uri":"https://localhost:8080/","height":590}},"source":["!pip install transformers"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/10/aeefced99c8a59d828a92cc11d213e2743212d3641c87c82d61b035a7d5c/transformers-2.3.0-py3-none-any.whl (447kB)\n","\r\u001b[K     |▊                               | 10kB 21.4MB/s eta 0:00:01\r\u001b[K     |█▌                              | 20kB 1.9MB/s eta 0:00:01\r\u001b[K     |██▏                             | 30kB 2.8MB/s eta 0:00:01\r\u001b[K     |███                             | 40kB 1.9MB/s eta 0:00:01\r\u001b[K     |███▋                            | 51kB 2.3MB/s eta 0:00:01\r\u001b[K     |████▍                           | 61kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 71kB 3.2MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 81kB 2.5MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 92kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 102kB 3.1MB/s eta 0:00:01\r\u001b[K     |████████                        | 112kB 3.1MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 122kB 3.1MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 133kB 3.1MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 143kB 3.1MB/s eta 0:00:01\r\u001b[K     |███████████                     | 153kB 3.1MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 163kB 3.1MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 174kB 3.1MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 184kB 3.1MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 194kB 3.1MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 204kB 3.1MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 215kB 3.1MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 225kB 3.1MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 235kB 3.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 245kB 3.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 256kB 3.1MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 266kB 3.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 276kB 3.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 286kB 3.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 296kB 3.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 307kB 3.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 317kB 3.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 327kB 3.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 337kB 3.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 348kB 3.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 358kB 3.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 368kB 3.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 378kB 3.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 389kB 3.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 399kB 3.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 409kB 3.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 419kB 3.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 430kB 3.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 440kB 3.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 450kB 3.1MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n","\u001b[K     |████████████████████████████████| 870kB 50.0MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.10.47)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n","Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n","\u001b[K     |████████████████████████████████| 1.0MB 45.5MB/s \n","\u001b[?25hRequirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n","Requirement already satisfied: botocore<1.14.0,>=1.13.47 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.13.47)\n","Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.2.1)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.47->boto3->transformers) (0.15.2)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.47->boto3->transformers) (2.6.1)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884629 sha256=b96d9728cad7018ab8767eef3223bef75535e7d1c1a6ea360cab048a96991877\n","  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n","Successfully built sacremoses\n","Installing collected packages: sacremoses, sentencepiece, transformers\n","Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 transformers-2.3.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IS6uez8zbBYp","colab_type":"code","outputId":"311463ba-e7fd-4525-9568-10e4432b527b","executionInfo":{"status":"ok","timestamp":1580236536600,"user_tz":300,"elapsed":9788,"user":{"displayName":"Michael Gunn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDLPGDDbbM21TTQ016rwUebXbiYn0V96tePqWjuFA=s64","userId":"01288302193981142685"}},"colab":{"base_uri":"https://localhost:8080/","height":173}},"source":["!pip install wget"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting wget\n","  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n","Building wheels for collected packages: wget\n","  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9681 sha256=cc40609501b38ba497b5945ad2f77dd65ed7b267a7cdfba9b3e493049991fded\n","  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n","Successfully built wget\n","Installing collected packages: wget\n","Successfully installed wget-3.2\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"cFzQQdQcvSHZ","colab_type":"text"},"source":["Basic Preprocessing Example"]},{"cell_type":"code","metadata":{"id":"3UthFeXuiqch","colab_type":"code","outputId":"87e8a5a5-0b59-4918-ff80-e5a0c97e148b","executionInfo":{"status":"ok","timestamp":1580236541747,"user_tz":300,"elapsed":14925,"user":{"displayName":"Michael Gunn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDLPGDDbbM21TTQ016rwUebXbiYn0V96tePqWjuFA=s64","userId":"01288302193981142685"}},"colab":{"base_uri":"https://localhost:8080/","height":64}},"source":["import wget\n","import os\n","import torch\n","import numpy as np\n","import pandas as pd\n","from transformers import BertModel, BertTokenizer"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"MYyQaiCjbaZO","colab_type":"code","outputId":"ad281478-fe67-44be-bf90-c2881b57a5a5","executionInfo":{"status":"ok","timestamp":1580236543965,"user_tz":300,"elapsed":17134,"user":{"displayName":"Michael Gunn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDLPGDDbbM21TTQ016rwUebXbiYn0V96tePqWjuFA=s64","userId":"01288302193981142685"}},"colab":{"base_uri":"https://localhost:8080/","height":86}},"source":["#download the dataset from the github repository of the webinar\n","url = 'https://github.com/theneuralbeing/bert-finetuning-webinar/blob/master/data.zip?raw=true'\n","if not os.path.exists('./data.zip'):\n","  wget.download(url, './data.zip')\n","  !unzip data.zip"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Archive:  data.zip\n","   creating: data/\n","  inflating: data/train.csv          \n","  inflating: data/validation.csv     \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6Aw5q-z_kr6O","colab_type":"code","colab":{}},"source":["bert_model = BertModel.from_pretrained('bert-base-uncased')\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eDehebBgo61-","colab_type":"text"},"source":["**PREPROCESSING TEXT FOR BERT**\n","1. tokenization\n","2. adding special tokens\n","3. padding\n","4. attention mask\n","5. segment ids (for sequence pairs)\n","6. convert sequence to integers (token ids)"]},{"cell_type":"code","metadata":{"id":"CzLbJDuPlNqm","colab_type":"code","outputId":"3e95bb5b-7f72-4f15-8e43-db2a21b15668","executionInfo":{"status":"ok","timestamp":1580236554656,"user_tz":300,"elapsed":27811,"user":{"displayName":"Michael Gunn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDLPGDDbbM21TTQ016rwUebXbiYn0V96tePqWjuFA=s64","userId":"01288302193981142685"}},"colab":{"base_uri":"https://localhost:8080/","height":225}},"source":["#preprocessing of input text\n","sentence = 'he likes playing football'\n","tokens = tokenizer.tokenize(sentence)\n","#add special tokens\n","tokens = ['[CLS]'] + tokens + ['[SEP]']\n","#add padding tokens\n","maxlen = 12\n","if len(tokens) > maxlen:\n","  tokens = tokens[:maxlen]\n","else:\n","  tokens = tokens + ['[PAD]' for _ in range(maxlen - len(tokens))]\n","tokens"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['[CLS]',\n"," 'he',\n"," 'likes',\n"," 'playing',\n"," 'football',\n"," '[SEP]',\n"," '[PAD]',\n"," '[PAD]',\n"," '[PAD]',\n"," '[PAD]',\n"," '[PAD]',\n"," '[PAD]']"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"jE_l2UXPlvgU","colab_type":"code","outputId":"33cef390-9893-4ccf-d6d1-ef17040aadd6","executionInfo":{"status":"ok","timestamp":1580236554657,"user_tz":300,"elapsed":27804,"user":{"displayName":"Michael Gunn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDLPGDDbbM21TTQ016rwUebXbiYn0V96tePqWjuFA=s64","userId":"01288302193981142685"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#build an attention mask to ignore padding tags\n","attn_mask = [1 if token != '[PAD]' else 0 for token in tokens]\n","attn_mask\n"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"_rfJUel0tNw6","colab_type":"code","outputId":"f3c63a59-88a3-4700-d4a3-d0d401689bfa","executionInfo":{"status":"ok","timestamp":1580236554660,"user_tz":300,"elapsed":27802,"user":{"displayName":"Michael Gunn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDLPGDDbbM21TTQ016rwUebXbiYn0V96tePqWjuFA=s64","userId":"01288302193981142685"}},"colab":{"base_uri":"https://localhost:8080/","height":225}},"source":["#if this was a 2-sentence task, there would be a segment id portion to label each sentence in the pair\n","sentence2 = 'he plays regularly at the playground with his friends'\n","tokens1 = tokenizer.tokenize(sentence)\n","tokens1 = ['[CLS]'] + tokens1 + ['[SEP]']\n","tokens2 = tokenizer.tokenize(sentence2)\n","tokens2 = tokens2 + ['[SEP]']\n","tokensP = tokens1 + tokens2\n","if len(tokensP) > maxlen:\n","  tokensP = tokensP[:maxlen-1] + ['[SEP]']\n","else:\n","  tokensP = tokensP + ['[PAD]' for _ in range(maxlen - len(tokensP))]\n","tokensP"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['[CLS]',\n"," 'he',\n"," 'likes',\n"," 'playing',\n"," 'football',\n"," '[SEP]',\n"," 'he',\n"," 'plays',\n"," 'regularly',\n"," 'at',\n"," 'the',\n"," '[SEP]']"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"CjpBPUjjwZR8","colab_type":"code","outputId":"76fa133a-7b3f-4be7-bc3b-006c516cf929","executionInfo":{"status":"ok","timestamp":1580236554660,"user_tz":300,"elapsed":27795,"user":{"displayName":"Michael Gunn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDLPGDDbbM21TTQ016rwUebXbiYn0V96tePqWjuFA=s64","userId":"01288302193981142685"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#segment ids for the sentence pair only\n","segment_ids = [0 for _ in range(len(tokens1))] + [1 for _ in range(maxlen-len(tokens1))]\n","segment_ids"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"kkR8IC0SpIF3","colab_type":"code","outputId":"ea230ddf-42a8-49c5-d5c4-819d5cc9a748","executionInfo":{"status":"ok","timestamp":1580236554662,"user_tz":300,"elapsed":27789,"user":{"displayName":"Michael Gunn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDLPGDDbbM21TTQ016rwUebXbiYn0V96tePqWjuFA=s64","userId":"01288302193981142685"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#taking the single-sentence example, we compute the token ids\n","token_ids = tokenizer.convert_tokens_to_ids(tokens)\n","token_ids"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[101, 2002, 7777, 2652, 2374, 102, 0, 0, 0, 0, 0, 0]"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"MYi-R9ZFskm3","colab_type":"code","outputId":"1d1d93d3-b8ce-486c-d3fb-d7d34e163264","executionInfo":{"status":"ok","timestamp":1580236554663,"user_tz":300,"elapsed":27783,"user":{"displayName":"Michael Gunn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDLPGDDbbM21TTQ016rwUebXbiYn0V96tePqWjuFA=s64","userId":"01288302193981142685"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#convert token ids and attention mask into a torch tensor object that can be recieved by the BERT model\n","token_ids = torch.tensor(token_ids).unsqueeze(0) #unsqueeze adds another dimension to the shape\n","attn_mask = torch.tensor(attn_mask).unsqueeze(0) #likewise, squeeze would remove a dimension from the shape\n","token_ids.shape, attn_mask.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([1, 12]), torch.Size([1, 12]))"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"1G4mbRYf1HUh","colab_type":"code","outputId":"ea45e98d-f7e7-4ac1-fcfa-e96859b2600d","executionInfo":{"status":"ok","timestamp":1580236554895,"user_tz":300,"elapsed":28008,"user":{"displayName":"Michael Gunn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDLPGDDbbM21TTQ016rwUebXbiYn0V96tePqWjuFA=s64","userId":"01288302193981142685"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["hidden_repr, cls_head = bert_model(token_ids, attention_mask=attn_mask)\n","#making cls representation from scratch because it is not representative of semantic content; it's designed for next-sentence prediction, not sentiment analysis.\n","cls_repr = hidden_repr[:0] #isolating the classification representation from the whole sentence representation\n","hidden_repr.shape, cls_head.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([1, 12, 768]), torch.Size([1, 768]))"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"awnlc-9HC_cW","colab_type":"text"},"source":["**LOAD DATA FOR SENTIMENT ANALYSIS**\n","[link text](https://)"]},{"cell_type":"code","metadata":{"id":"CDChJD25DE_x","colab_type":"code","colab":{}},"source":["from torch.utils.data import Dataset, DataLoader"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HTwUiGR9EXOM","colab_type":"code","colab":{}},"source":["class LoadDataset(Dataset):\n","\n","  def __init__(self, n, filename, maxlen=64):\n","    self.n = n\n","    self.df = pd.read_csv(filename, delimiter=',', nrows=n)\n","    self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","    self.maxlen = maxlen\n","\n","\n","  #dataset class is required to return the max length of any given string\n","  def __len__(self):\n","    return len(self.df)\n","\n","  #preprocessing and returning weights by using the data loader\n","  def __getitem__(self, index):\n","    sentence = self.df.loc[index, 'review']\n","    label = self.df.loc[index, 'sentiment']\n","    #tokenization, special tokens, padding, attention mask, token ids\n","    tokens = self.tokenizer.tokenize(sentence)                            #tokenization\n","    tokens = ['[CLS]'] + tokens + ['[SEP]']                               #special tokens\n","    if len(tokens) < self.maxlen:                                         #padding\n","      tokens = tokens + ['[PAD]' for _ in range(self.maxlen - len(tokens))]\n","    else:\n","      tokens = tokens[:self.maxlen-1] + ['[SEP]']\n","    token_ids = self.tokenizer.convert_tokens_to_ids(tokens)              #token ids\n","    token_ids = torch.tensor(token_ids)\n","    attn_mask = (token_ids != 0).long()                                   #attention mask (if token id is not 0, return true as integer (1))\n","    #print(self.df.size)\n","\n","    return token_ids, attn_mask, label #this would also include the position tag if a next-sentence model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"H71hYLTCKoqA","colab_type":"code","outputId":"1b95c6c6-7982-41e4-a9b7-68f9167a8a00","executionInfo":{"status":"ok","timestamp":1580236555788,"user_tz":300,"elapsed":28887,"user":{"displayName":"Michael Gunn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDLPGDDbbM21TTQ016rwUebXbiYn0V96tePqWjuFA=s64","userId":"01288302193981142685"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["train_set = LoadDataset(filename='data/train.csv', maxlen=64, n=4500)\n","val_set = LoadDataset(filename='data/validation.csv', maxlen=64, n=500)\n","print(train_set[0][0].shape, train_set[0][1].shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["torch.Size([64]) torch.Size([64])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kEVlQJgROX8e","colab_type":"code","colab":{}},"source":["train_loader = DataLoader(train_set, batch_size=32, num_workers=5)\n","val_loader = DataLoader(val_set, batch_size=32, num_workers=5)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oI31JUTQOphd","colab_type":"text"},"source":["**TRAIN THE BERT MODEL FOR SENTIMENT ANALYSIS**\n","1. Set the model to train mode\n","2. Spart the epoch\n","3. For every batch in the data loader:\n","  a) zero out gradients\n","  b) get output of the model\n","  c) compute loss\n","  d) backpropagate gradients\n","  e) optimizer step\n","  f) at the end of epoch, validate data\n","4. Finally, save the model"]},{"cell_type":"code","metadata":{"id":"tMngBwyFOvyV","colab_type":"code","colab":{}},"source":["from torch import nn"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mEtpmexUPhuo","colab_type":"code","colab":{}},"source":["class SentimentClassifier(nn.Module): #custom models will always inherit from the nn.Module class of torch\n","\n","  def __init__(self):\n","    super(SentimentClassifier, self).__init__()\n","    self.bert_layer = BertModel.from_pretrained('bert-base-uncased')\n","    self.dropout = nn.Dropout(0.1)\n","    self.classifier = nn.Linear(768, 1) #N.B. that 768 is the length of the 3rd dimension of the unsqueezed hidden representation and classification tag heads\n","  \n","  def forward(self, seq, attn_masks):\n","    \"\"\"\n","\t\tInputs:\n","\t\t\tseq : Tensor of shape [B, T] containing token ids of sequences\n","\t\t\tattn_masks : Tensor of shape [B, T] containing attenntion masks to be used to avoid co...\n","\t\t\"\"\"\n","    seq_repr, _ = self.bert_layer(seq, attention_mask=attn_masks)\n","    cls_repr = seq_repr[:,0] #the first token is always the classification token\n","    logits = self.classifier(cls_repr)\n","    return logits"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZG4jnKEGRvCZ","colab_type":"code","colab":{}},"source":["model = SentimentClassifier()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8J3vIlHNR5qH","colab_type":"code","colab":{}},"source":["from torch.optim import Adam\n","from torch.nn import BCEWithLogitsLoss\n","\n","criterion = BCEWithLogitsLoss()\n","optimizer = Adam(model.parameters(), lr=0.00002)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4X1wC2SXJ6BP","colab_type":"code","outputId":"405bbee8-1d5f-4f35-9207-1b16c55e5e28","executionInfo":{"status":"ok","timestamp":1580236558156,"user_tz":300,"elapsed":31235,"user":{"displayName":"Michael Gunn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDLPGDDbbM21TTQ016rwUebXbiYn0V96tePqWjuFA=s64","userId":"01288302193981142685"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["if torch.cuda.is_available():\n","  device = 'cuda'\n","  print(\"Using the GPU: \" + torch.cuda.get_device_name(0))\n","else:\n","  device = 'cpu'\n","  print(\"No GPU available. Using CPU instead.\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using the GPU: Tesla T4\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RABm6Dupvd60","colab_type":"text"},"source":["Training Methods"]},{"cell_type":"code","metadata":{"id":"99ouYl4-KD8x","colab_type":"code","colab":{}},"source":["from time import time"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zJjUu0miT4xY","colab_type":"code","colab":{}},"source":["def logits_accuracy(logits, labels):\n","  probs = torch.sigmoid(logits.unsqueeze(-1))\n","  preds = (probs > 0.5).long()\n","  acc = (preds.squeeze() == labels).float().mean()\n","  return acc"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lp4TpC42MoQ8","colab_type":"code","colab":{}},"source":["def evaluate(model, criterion, val_loader, device):\n","  total_loss, total_accuracy = 0, 0\n","  model.eval() #set the model to evaluation mode\n","  count = 0\n","  for (seq, attn_masks, labels) in val_loader:\n","    count += 1\n","    seq, attn_masks, labels = seq.to(device), attn_masks.to(device), labels.to(device)\n","    #get logit predictions\n","    val_logits = model(seq, attn_masks)\n","    #calculate loss\n","    val_loss = criterion(val_logits.squeeze(0).squeeze(-1), labels.float())\n","    total_loss += val_loss.item()\n","    #calculate validation accuracy\n","    total_accuracy += logits_accuracy(val_logits, labels)\n","  return total_loss / count, total_accuracy / count"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NB3swDT8KORB","colab_type":"code","colab":{}},"source":["def train(model, criterion, optimizer, train_loader, val_loader, device, epochs=4, print_every=100):\n","  #set the device to use CUDA and the graphics card\n","  model.to(device)\n","  model.train() #set the model to training mode\n","  print(\"Training started...\")\n","\n","  for epoch in range(epochs): #4-5 epochs should be optimal\n","    print(\"Epoch {}\".format(epoch))\n","    t1 = time()\n","    #load the batches from the data loader\n","    for i, (seq, attn_masks, labels) in enumerate(train_loader):\n","      optimizer.zero_grad()                                                               #zero out the gradients\n","      seq, attn_masks, labels = seq.to(device), attn_masks.to(device), labels.to(device)\n","      logits = model(seq, attn_masks)                                                     #get the output of the model\n","      loss = criterion(logits.squeeze(0).squeeze(-1), labels.float())                                #calculate the loss\n","      loss.backward()                                                                     #backpropagation\n","      nn.utils.clip_grad_norm_(model.parameters(), 1) #clipping gradients to tackle exploding gradients\n","      optimizer.step()                                                                    #optimizer step\n","      if (i + 1) % print_every == 0:\n","        print(\"Iteration {} ==== Loss {}\".format(i+1, loss.item()))\n","    print(\"====Validating Data====\")\n","    mean_val_loss, mean_val_acc = evaluate(model, criterion, val_loader, device)                            #validate data\n","    print(\"Validation Loss: {}\\nValidation Accuracy: {}\".format(mean_val_loss, mean_val_acc))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UusTfNfe5NQt","colab_type":"code","outputId":"252a9b39-4bfe-4ca4-e1b3-15aba690d0d5","executionInfo":{"status":"ok","timestamp":1580236561941,"user_tz":300,"elapsed":35001,"user":{"displayName":"Michael Gunn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDLPGDDbbM21TTQ016rwUebXbiYn0V96tePqWjuFA=s64","userId":"01288302193981142685"}},"colab":{"base_uri":"https://localhost:8080/","height":225}},"source":["#confirm that the GPU memory is available (this must be done or else I get a \"RuntimeError: CUDA out of memory.\" message and the model doesn't train)\n","!pip install gputil\n","import GPUtil\n","GPUtil.showUtilization()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting gputil\n","  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n","Building wheels for collected packages: gputil\n","  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gputil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7410 sha256=ad9229da469d7ebf8d9d7274311ffd210ed45b6ee787872fbded2132924fbf97\n","  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n","Successfully built gputil\n","Installing collected packages: gputil\n","Successfully installed gputil-1.4.0\n","| ID | GPU | MEM |\n","------------------\n","|  0 |  0% |  0% |\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fPCom_TkPhc8","colab_type":"code","outputId":"0faf8bf1-007b-4205-a8ac-9772777dec28","executionInfo":{"status":"ok","timestamp":1580236902486,"user_tz":300,"elapsed":375538,"user":{"displayName":"Michael Gunn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDLPGDDbbM21TTQ016rwUebXbiYn0V96tePqWjuFA=s64","userId":"01288302193981142685"}},"colab":{"base_uri":"https://localhost:8080/","height":990}},"source":["train(model, criterion, optimizer, train_loader, val_loader, device, epochs=5, print_every=20)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Training started...\n","Epoch 0\n","Iteration 20 ==== Loss 0.607633113861084\n","Iteration 40 ==== Loss 0.5047159194946289\n","Iteration 60 ==== Loss 0.5543547868728638\n","Iteration 80 ==== Loss 0.5726668834686279\n","Iteration 100 ==== Loss 0.37867027521133423\n","Iteration 120 ==== Loss 0.46347641944885254\n","Iteration 140 ==== Loss 0.38285166025161743\n","====Validating Data====\n","Validation Loss: 0.4667821926996112\n","Validation Accuracy: 0.7890625\n","Epoch 1\n","Iteration 20 ==== Loss 0.2442961484193802\n","Iteration 40 ==== Loss 0.4197276532649994\n","Iteration 60 ==== Loss 0.677882194519043\n","Iteration 80 ==== Loss 0.31491440534591675\n","Iteration 100 ==== Loss 0.07899954169988632\n","Iteration 120 ==== Loss 0.21755670011043549\n","Iteration 140 ==== Loss 0.24157455563545227\n","====Validating Data====\n","Validation Loss: 0.5969902351498604\n","Validation Accuracy: 0.7777343988418579\n","Epoch 2\n","Iteration 20 ==== Loss 0.1003086268901825\n","Iteration 40 ==== Loss 0.2278057336807251\n","Iteration 60 ==== Loss 0.11038534343242645\n","Iteration 80 ==== Loss 0.011089452542364597\n","Iteration 100 ==== Loss 0.0025970330461859703\n","Iteration 120 ==== Loss 0.4921996593475342\n","Iteration 140 ==== Loss 0.17391568422317505\n","====Validating Data====\n","Validation Loss: 0.7392060041893274\n","Validation Accuracy: 0.799609363079071\n","Epoch 3\n","Iteration 20 ==== Loss 0.0043189022690057755\n","Iteration 40 ==== Loss 0.014842169359326363\n","Iteration 60 ==== Loss 0.013989794068038464\n","Iteration 80 ==== Loss 0.0010365123162046075\n","Iteration 100 ==== Loss 0.002487841062247753\n","Iteration 120 ==== Loss 0.035432156175374985\n","Iteration 140 ==== Loss 0.0018003900768235326\n","====Validating Data====\n","Validation Loss: 0.960307789966464\n","Validation Accuracy: 0.791796863079071\n","Epoch 4\n","Iteration 20 ==== Loss 0.020336225628852844\n","Iteration 40 ==== Loss 0.0006157022435218096\n","Iteration 60 ==== Loss 0.0008060293621383607\n","Iteration 80 ==== Loss 0.00041261306614615023\n","Iteration 100 ==== Loss 0.00043954155989922583\n","Iteration 120 ==== Loss 0.0004446296370588243\n","Iteration 140 ==== Loss 0.009466025978326797\n","====Validating Data====\n","Validation Loss: 1.1979804430156946\n","Validation Accuracy: 0.805468738079071\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TGP-9F9t9Dv3","colab_type":"code","colab":{}},"source":["#saving our model\n","save_path = 'checkpoints'\n","if not os.path.isdir(save_path):\n","  os.mkdir(save_path)\n","torch.save({\n","    'model_state_dict':model.state_dict(),\n","    'optimizer_state_dict':optimizer.state_dict()\n","}, os.path.join(save_path, 'model.pth'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ktYLOSAfDBrB","colab_type":"code","colab":{}},"source":["#for inference\n","torch.save(model.state_dict(), os.path.join(save_path, 'inference.pth'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HdyGxb0OCZiX","colab_type":"code","outputId":"e2fd1e45-3c87-44b9-8478-affb557d52d0","executionInfo":{"status":"ok","timestamp":1580236919614,"user_tz":300,"elapsed":392651,"user":{"displayName":"Michael Gunn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDLPGDDbbM21TTQ016rwUebXbiYn0V96tePqWjuFA=s64","userId":"01288302193981142685"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["ls checkpoints/"],"execution_count":0,"outputs":[{"output_type":"stream","text":["inference.pth  model.pth\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NEDzdZMTD02Z","colab_type":"text"},"source":["**PREDICTIONS WITH THE MODEL**"]},{"cell_type":"code","metadata":{"id":"C7swnA2BG0iu","colab_type":"code","colab":{}},"source":["#convert a new message into WordPiece tokens, and then into the input vectors\n","def preprocess(message, maxlen=64):\n","  #tokenization, special tokens, padding, attention mask, token ids\n","  tokens = tokenizer.tokenize(message)                            #tokenization\n","  tokens = ['[CLS]'] + tokens + ['[SEP]']                         #special tokens\n","  if len(tokens) < maxlen:                                        #padding\n","    tokens = tokens + ['[PAD]' for _ in range(maxlen - len(tokens))]\n","  else:\n","    tokens = tokens[:self.maxlen-1] + ['[SEP]']\n","  token_ids = tokenizer.convert_tokens_to_ids(tokens)             #token ids\n","  token_ids = torch.tensor(token_ids)\n","  attn_mask = (token_ids != 0).long()   \n","  return token_ids, attn_mask"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bHWpESSUD7bV","colab_type":"code","colab":{}},"source":["def predict(model, seq, attn_masks, device):\n","  total_loss = 0\n","  model.eval()\n","  #load the data\n","  seq, attn_masks = seq.unsqueeze(0).to(device), attn_masks.unsqueeze(0).to(device)\n","  #get logit predictions\n","  logits = model(seq, attn_masks)\n","  probs = torch.sigmoid(logits.unsqueeze(-1))\n","  preds = (probs > 0.5).long()\n","  preds = preds[0][0].tolist()\n","  return preds"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"E1yBGLfiE5Oi","colab_type":"code","outputId":"802d912c-eadb-463b-82a9-b3a65fef0d78","executionInfo":{"status":"ok","timestamp":1580236919759,"user_tz":300,"elapsed":392782,"user":{"displayName":"Michael Gunn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDLPGDDbbM21TTQ016rwUebXbiYn0V96tePqWjuFA=s64","userId":"01288302193981142685"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["#example = \"The new Star Wars movie was terrible! I did not like the acting. The writers should be fired. The characters were very poorly developed. I wish that I could have my money back!\"\n","#example = \"Citizen Caine was the best movie I ever saw. You will become smarter if you watch it.\"\n","#example = \"The movie was mediocre. It had some good parts, but I wish the director was Michael Bay and not Steven Spielberg. That would have been more action-packed.\"\n","#example = \"I have no opinion on this movie.\"\n","example = \"I enjoyed the movie a lot. It was very fun. My kids loved it!\"\n","example_token_ids, example_attn_masks = preprocess(example)\n","print(example_token_ids.shape, example_attn_masks.shape)\n","\n","prediction = predict(model, example_token_ids, example_attn_masks, device)\n","print(\"The review has {} sentiment.\".format('negative' if prediction[0] == 0 else 'positive'))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["torch.Size([64]) torch.Size([64])\n","The review has positive sentiment.\n"],"name":"stdout"}]}]}